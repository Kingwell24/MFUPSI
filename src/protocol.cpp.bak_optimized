#include "protocol.h"
#include <algorithm>
#include <cmath>
#include <random>
#include <iostream>
#include <numeric>

/**
 * 构造函数
 */
MFUPSIProtocol::MFUPSIProtocol(const Config_t& cfg) : config_(cfg) {
    clients_.resize(cfg.num_clients);
    for (size_t i = 0; i < cfg.num_clients; i++) {
        clients_[i].client_id = i;
    }
    reset_metrics();
    
    // 初始化LWE密钥
    pir_lwe_key_.dimension = cfg.lwe_dimension;
}

/**
 * 生成全局密钥
 */
void MFUPSIProtocol::generate_keys() {
    std::mt19937_64 rng(std::random_device{}());
    std::uniform_int_distribution<uint64_t> dist;
    
    key_k1_ = dist(rng);
    key_k2_ = dist(rng);
    key_kr_ = dist(rng);
}

/**
 * 为客户端生成随机数据集
 */
void MFUPSIProtocol::generate_client_data(Client& client, size_t size) {
    std::mt19937_64 rng(std::random_device{}());
    std::uniform_int_distribution<uint64_t> dist;
    
    while (client.data_set.size() < size) {
        client.data_set.insert(dist(rng));
    }
}

/**
 * 生成稀疏向量
 * Algorithm 4: RandVector(K_2, x, d_1, w)
 */
MFUPSIProtocol::VectorType MFUPSIProtocol::generate_rand_vector(uint64_t element) {
    auto sparse_uint8 = Utils::sparse_vector(key_k2_, element, config_.partition_size, config_.band_width);
    VectorType result(sparse_uint8.size());
    for (size_t i = 0; i < sparse_uint8.size(); i++) {
        result[i] = static_cast<uint64_t>(sparse_uint8[i]);
    }
    return result;
}

/**
 * 构建带状矩阵和目标向量
 */
void MFUPSIProtocol::build_linear_system(
    const std::vector<uint64_t>& elements,
    MatrixType& M,
    VectorType& y
) {
    size_t m = elements.size();
    M.resize(m, VectorType(config_.partition_size, 0));
    y.resize(m);
    
    for (size_t i = 0; i < m; i++) {
        // 生成稀疏向量作为矩阵的一行
        auto sparse_vec = generate_rand_vector(elements[i]);
        for (size_t j = 0; j < config_.partition_size; j++) {
            M[i][j] = sparse_vec[j];
        }
        
        // 生成目标值
        y[i] = Utils::prf_value(key_kr_, elements[i]) % config_.modulus;
    }
}

/**
 * 分区编码
 * Algorithm 3: EncodePartition(P_j, K_2, K_r, d_1, w)
 */
MFUPSIProtocol::VectorType MFUPSIProtocol::encode_partition(
    const std::vector<uint64_t>& partition_elements
) {
    if (partition_elements.empty()) {
        return VectorType(config_.partition_size, 0);
    }
    
    // 构建线性系统 M * e = y
    MatrixType M;
    VectorType y;
    build_linear_system(partition_elements, M, y);
    
    // 高斯消元求解
    VectorType e_j = Matrix::gaussian_elimination(M, y, config_.modulus);
    
    // 确保输出维度正确
    if (e_j.size() != config_.partition_size) {
        e_j.resize(config_.partition_size, 0);
    }
    
    return e_j;
}

/**
 * 客户端本地编码
 * Algorithm 2: ClientEncode(X_i, K_1, K_2, K_r, d_1, w, epsilon)
 */
MFUPSIProtocol::MatrixType MFUPSIProtocol::client_encode(
    const std::set<uint64_t>& data_set
) {
    // 步骤1: 初始化编码矩阵
    MatrixType E_i(config_.partition_size, VectorType(config_.num_partitions, 0));
    
    // 步骤2: 将数据分配到分区
    std::map<size_t, std::vector<uint64_t>> partitions;
    
    for (const auto& element : data_set) {
        size_t j = Utils::hash_partition(key_k1_, element) % config_.num_partitions;
        partitions[j].push_back(element);
    }
    
    // 步骤3: 对每个分区进行编码
    for (const auto& [partition_id, elements] : partitions) {
        auto e_j = encode_partition(elements);
        
        // 将e_j放入编码矩阵的第partition_id列
        if (partition_id < config_.num_partitions) {
            for (size_t i = 0; i < config_.partition_size; i++) {
                E_i[i][partition_id] = e_j[i];
            }
        }
    }
    
    return E_i;
}

/**
 * 生成掩码矩阵
 */
MFUPSIProtocol::MatrixType MFUPSIProtocol::generate_mask_matrix(
    size_t rows, size_t cols
) {
    return Matrix::random_matrix(rows, cols, config_.modulus);
}

/**
 * 生成全局掩码矩阵（Setup阶段初始化，不计入计时）
 */
void MFUPSIProtocol::generate_global_masks() {
    global_masks_.resize(config_.num_clients);
    for (size_t i = 0; i < config_.num_clients; i++) {
        global_masks_[i] = generate_mask_matrix(
            config_.partition_size, config_.num_partitions
        );
    }
}

/**
 * Setup阶段
 */
void MFUPSIProtocol::setup_phase() {
    std::cout << "开始Setup阶段..." << std::endl;
    
    // 生成全局密钥
    generate_keys();
    
    // 初始化LWE密钥（用于PIR）
    initialize_lwe_key();
    
    // 步骤1: 为每个客户端生成数据集
    for (auto& client : clients_) {
        generate_client_data(client, config_.dataset_size);
    }
    
    // 步骤2: 生成全局掩码（在计时前）
    generate_global_masks();
    
    // 步骤3: 每个客户端进行本地编码（每个客户端各自计时）
    double total_client_time = 0.0;
    size_t total_client_comm = 0;
    
    for (size_t i = 0; i < clients_.size(); i++) {
        auto& client = clients_[i];
        
        // 客户端编码计时
        Utils::Timer timer;
        timer.start();
        
        // 客户端编码
        client.encoding_matrix = client_encode(client.data_set);
        
        // 掩码添加（使用预生成的全局掩码）
        client.mask_matrix = global_masks_[i];
        client.masked_encoding = Matrix::matrix_add(
            client.encoding_matrix,
            client.mask_matrix,
            config_.modulus
        );
        
        timer.stop();
        total_client_time += timer.elapsed_ms();
    }
    
    metrics_.setup_client_encoding_time_ms = total_client_time;
    
    // 计算通信开销（在停止计时后）
    metrics_.setup_client_comm_bytes = clients_.size() * Utils::matrix_size_bytes(
        config_.partition_size, config_.num_partitions
    );
    
    // 步骤4: 服务器聚合
    server_aggregate();
    
    std::cout << "Setup阶段完成" << std::endl;
    std::cout << "  客户端编码耗时: " << metrics_.setup_client_encoding_time_ms << " ms" << std::endl;
    std::cout << "  服务器聚合耗时: " << metrics_.setup_server_aggregation_time_ms << " ms" << std::endl;
    std::cout << "  客户端上传通信: " << metrics_.setup_client_comm_bytes / (1024.0 * 1024.0) << " MB" << std::endl;
}

/**
 * 服务器聚合
 */
void MFUPSIProtocol::server_aggregate() {
    Utils::Timer timer;
    timer.start();
    
    // 初始化全局编码为零矩阵
    server_.global_encoding = Matrix::zero_matrix(
        config_.partition_size, config_.num_partitions
    );
    
    // 聚合所有客户端的掩码编码
    for (const auto& client : clients_) {
        server_.global_encoding = Matrix::matrix_add(
            server_.global_encoding,
            client.masked_encoding,
            config_.modulus
        );
    }
    
    timer.stop();
    metrics_.setup_server_aggregation_time_ms = timer.elapsed_ms();
}

/**
 * Update阶段
 */
void MFUPSIProtocol::update_phase(size_t num_clients_to_update) {
    std::cout << "开始Update阶段..." << std::endl;
    
    num_clients_to_update = std::min(num_clients_to_update, clients_.size());
    
    double total_client_time = 0.0;
    size_t total_client_comm = 0;
    std::mt19937_64 rng(std::random_device{}());
    std::uniform_int_distribution<uint64_t> dist;
    
    for (size_t i = 0; i < num_clients_to_update; i++) {
        auto& client = clients_[i];
        
        std::set<uint64_t> X_add, X_del;
        size_t update_count = std::min(config_.num_updates, config_.dataset_size / 100);
        
        for (size_t j = 0; j < update_count / 2; j++) {
            X_add.insert(dist(rng));
        }
        
        std::vector<uint64_t> data_vec(client.data_set.begin(), client.data_set.end());
        std::shuffle(data_vec.begin(), data_vec.end(), rng);
        for (size_t j = 0; j < update_count / 2 && j < data_vec.size(); j++) {
            X_del.insert(data_vec[j]);
        }
        
        while (X_add.size() < X_del.size()) {
            X_add.insert(dist(rng));
        }
        while (X_del.size() < X_add.size() && X_del.size() < data_vec.size()) {
            X_del.insert(data_vec[X_del.size()]);
        }
        
        Utils::Timer timer;
        timer.start();
        
        for (const auto& elem : X_add) {
            client.data_set.insert(elem);
        }
        for (const auto& elem : X_del) {
            client.data_set.erase(elem);
        }
        
        auto delta_E = client_incremental_update(client, X_add, X_del);
        
        auto new_mask = generate_mask_matrix(
            config_.partition_size, config_.num_partitions
        );
        auto delta_E_tilde = Matrix::matrix_add(delta_E, new_mask, config_.modulus);
        client.mask_matrix = new_mask;
        
        timer.stop();
        total_client_time += timer.elapsed_ms();
        total_client_comm += Utils::matrix_size_bytes(
            config_.partition_size, config_.num_partitions
        );
    }
    
    for (size_t i = num_clients_to_update; i < clients_.size(); i++) {
        auto& client = clients_[i];
        
        Utils::Timer timer;
        timer.start();
        
        auto new_mask = generate_mask_matrix(
            config_.partition_size, config_.num_partitions
        );
        client.masked_encoding = Matrix::matrix_add(
            client.encoding_matrix,
            new_mask,
            config_.modulus
        );
        client.mask_matrix = new_mask;
        
        timer.stop();
        total_client_time += timer.elapsed_ms();
        total_client_comm += Utils::matrix_size_bytes(
            config_.partition_size, config_.num_partitions
        );
    }
    
    metrics_.update_client_time_ms = total_client_time;
    metrics_.update_client_comm_bytes = total_client_comm;
    
    server_incremental_update();
    
    std::cout << "Update阶段完成" << std::endl;
    std::cout << "  客户端更新耗时: " << metrics_.update_client_time_ms << " ms" << std::endl;
    std::cout << "  服务器更新耗时: " << metrics_.update_server_time_ms << " ms" << std::endl;
    std::cout << "  客户端上传通信: " << metrics_.update_client_comm_bytes / (1024.0 * 1024.0) << " MB" << std::endl;
}

/**
 * 客户端增量编码
 */
MFUPSIProtocol::MatrixType MFUPSIProtocol::client_incremental_update(
    Client& client,
    const std::set<uint64_t>& X_add,
    const std::set<uint64_t>& X_del
) {
    std::set<size_t> affected_partitions;
    
    for (const auto& elem : X_add) {
        size_t j = Utils::hash_partition(key_k1_, elem) % config_.num_partitions;
        affected_partitions.insert(j);
    }
    for (const auto& elem : X_del) {
        size_t j = Utils::hash_partition(key_k1_, elem) % config_.num_partitions;
        affected_partitions.insert(j);
    }
    
    MatrixType delta_E = Matrix::zero_matrix(
        config_.partition_size, config_.num_partitions
    );
    
    for (size_t j : affected_partitions) {
        std::vector<uint64_t> partition_elements;
        
        for (const auto& elem : client.data_set) {
            if (Utils::hash_partition(key_k1_, elem) % config_.num_partitions == j) {
                partition_elements.push_back(elem);
            }
        }
        
        auto e_j_new = encode_partition(partition_elements);
        
        VectorType delta_e_j = e_j_new;
        
        for (size_t i = 0; i < config_.partition_size; i++) {
            delta_E[i][j] = delta_e_j[i];
        }
    }
    
    client.encoding_matrix = Matrix::matrix_add(
        client.encoding_matrix,
        delta_E,
        config_.modulus
    );
    
    return delta_E;
}

/**
 * 服务器增量更新
 */
void MFUPSIProtocol::server_incremental_update() {
    Utils::Timer timer;
    timer.start();
    
    server_.global_encoding = Matrix::zero_matrix(
        config_.partition_size, config_.num_partitions
    );
    
    for (const auto& client : clients_) {
        auto masked_enc = Matrix::matrix_add(
            client.encoding_matrix,
            client.mask_matrix,
            config_.modulus
        );
        server_.global_encoding = Matrix::matrix_add(
            server_.global_encoding,
            masked_enc,
            config_.modulus
        );
    }
    
    timer.stop();
    metrics_.update_server_time_ms = timer.elapsed_ms();
}

// ===== PIR相关新增函数 =====

/**
 * 计算z维PIR中每个维度的大小L = ceil(b^(1/z))
 */
size_t MFUPSIProtocol::compute_pir_dimension_size() {
    size_t b = config_.num_partitions;
    size_t z = config_.pir_dimension;
    
    // L = ceil(b^(1/z))
    double L_float = std::pow(static_cast<double>(b), 1.0 / static_cast<double>(z));
    return static_cast<size_t>(std::ceil(L_float));
}

/**
 * 将分区索引j映射到z维超立方体坐标
 * 将j视为基数L的数字，分解为z个坐标
 */
std::vector<size_t> MFUPSIProtocol::compute_hypercube_coordinates(size_t j) {
    size_t z = config_.pir_dimension;
    size_t L = compute_pir_dimension_size();
    
    std::vector<size_t> coordinates(z);
    
    // 从高位到低位逐个提取坐标
    // j = idx_1 * L^(z-1) + idx_2 * L^(z-2) + ... + idx_z * L^0
    for (size_t i = 0; i < z; i++) {
        size_t exponent = z - 1 - i;
        size_t divisor = static_cast<size_t>(std::pow(static_cast<double>(L), static_cast<double>(exponent)));
        coordinates[i] = (j / divisor) % L;
    }
    
    return coordinates;
}

/**
 * 初始化LWE密钥：生成随机秘密向量
 */
void MFUPSIProtocol::initialize_lwe_key() {
    size_t N_lwe = config_.lwe_dimension;
    pir_lwe_key_.secret_key.resize(N_lwe);
    
    std::mt19937_64 rng(std::random_device{}());
    std::uniform_int_distribution<uint64_t> dist(0, config_.modulus - 1);
    
    for (size_t i = 0; i < N_lwe; i++) {
        pir_lwe_key_.secret_key[i] = dist(rng);
    }
}

/**
 * 生成GSW密文矩阵：大小(2*N_lwe) × (2*N_lwe)
 * 这里只是生成随机矩阵用于模拟计算开销
 */
MFUPSIProtocol::GSWCiphertext MFUPSIProtocol::generate_gsw_ciphertext_for_coordinate(
    size_t coordinate, size_t L
) {
    GSWCiphertext ct;
    ct.dimension = config_.lwe_dimension;
    
    size_t gsw_dim = 2 * config_.lwe_dimension;
    ct.matrix = Matrix::random_matrix(gsw_dim, gsw_dim, config_.modulus);
    
    return ct;
}

/**
 * 生成z个选择向量，每个对应超立方体的一个维度
 * 
 * 算法步骤：
 * 1. 计算元素所在的分区j
 * 2. 将j映射到z维坐标 (idx_1, ..., idx_z)
 * 3. 对于第d维，生成一个选择向量，在idx_d位置设置非零值
 */
std::vector<MFUPSIProtocol::VectorType> MFUPSIProtocol::generate_z_selection_vectors(
    size_t element
) {
    // 第一维使用稀疏向量（与原来的RandVector一致）
    VectorType v1 = generate_rand_vector(element);
    
    // 计算分区索引
    size_t j = Utils::hash_partition(key_k1_, element) % config_.num_partitions;
    
    // 映射到z维坐标
    std::vector<size_t> coords = compute_hypercube_coordinates(j);
    
    size_t z = config_.pir_dimension;
    size_t L = compute_pir_dimension_size();
    
    std::vector<VectorType> z_selection_vectors;
    z_selection_vectors.push_back(v1);  // 第一维选择向量
    
    // 生成后续z-1维的选择向量
    for (size_t dim = 1; dim < z; dim++) {
        VectorType v_dim(L, 0);
        // 在第coord[dim]位置设置选择标记
        if (coords[dim] < L) {
            v_dim[coords[dim]] = 1;  // 简化版：直接设置为1
        }
        z_selection_vectors.push_back(v_dim);
    }
    
    return z_selection_vectors;
}

/**
 * 模拟z维PIR服务器处理：维度折叠
 * 
 * 这是最复杂的部分，需要模拟z轮的同态运算
 * 
 * 算法流程：
 * 1. 初始化当前编码矩阵为E_total（d_1 × b）
 * 2. 对于第1维：
 *    - 使用v1（长度b）与E_total相乘：result1 = v1^T · E_total（1 × d_1）
 * 3. 对于第2维到第z维：
 *    - 通过GSW外部积对结果进行维度压缩
 *    - 每一维的折叠将数据量从b/L^(i-1) 压缩到 b/L^i
 * 
 * 总的矩阵乘法复杂度：约 z × b 次运算
 */
MFUPSIProtocol::VectorType MFUPSIProtocol::server_process_pir_query_z_dimension(
    const std::vector<VectorType>& z_selection_vectors
) {
    if (z_selection_vectors.empty()) {
        return VectorType(config_.partition_size, 0);
    }
    
    size_t z = config_.pir_dimension;
    size_t L = compute_pir_dimension_size();
    size_t b = config_.num_partitions;
    size_t d1 = config_.partition_size;
    size_t N_lwe = config_.lwe_dimension;
    
    // 初始数据结构：服务器保有d_1 × b的编码矩阵 E_total
    // 维度折叠的目的是通过GSW同态运算逐维压缩
    
    // ===== 第一维处理（维度1）=====
    // 输入：选择向量v1（长度b），编码矩阵E_total（d_1 × b）
    // 操作：向量-矩阵乘法：result1 = v1^T · E_total -> (1 × d_1)
    // 计算复杂度：O(b * d_1)
    
    const auto& v1 = z_selection_vectors[0];
    
    // 如果第一个选择向量长度不匹配，进行零填充
    VectorType v1_padded = v1;
    if (v1_padded.size() < b) {
        v1_padded.resize(b, 0);
    } else if (v1_padded.size() > b) {
        v1_padded.resize(b);
    }
    
    // 执行第一维的同态乘法
    VectorType result = Matrix::vector_matrix_multiply(
        v1_padded,
        server_.global_encoding,
        config_.modulus
    );
    
    // ===== 后续维度处理（维度2到z）=====
    // 每一维都需要执行GSW外部积来"提取"特定维度的信息
    // 
    // 算法流程：
    // 对于第d维（d = 2, ..., z）：
    //   1. 上一维得到的结果进行接收（大小从b逐维缩小）
    //   2. 生成当前维度的GSW密文矩阵
    //   3. 执行GSW外部积：GSW_Matrix × LWE_Vector
    //   4. 得到当前维度的乘积结果
    // 
    // 为了模拟计算开销，我们需要真实执行这些矩阵乘法
    
    for (size_t dim = 1; dim < z; dim++) {
        // 当前维度应该处理的数据规模
        // 在第dim维，我们已对前dim-1维进行了折叠
        // 数据量从b，缩减到b/L, b/L^2, ..., b/L^(dim-1)
        
        size_t current_data_scale = b;
        for (size_t j = 0; j < dim - 1; j++) {
            current_data_scale = (current_data_scale + L - 1) / L;
        }
        
        if (dim < z_selection_vectors.size()) {
            const auto& v_dim = z_selection_vectors[dim];
            
            // ===== 模拟GSW同态扩展 =====
            // 原理：客户端发来的是z个GSW密文，代表z个维度的选择信息
            // 服务器需要通过GSW外部积将其"展开"为完整的选择向量
            // 
            // 为了简化但保持计算量的准确性，我们执行以下步骤：
            // 1. 构建一个临时矩阵代表当前维度的同态处理中间结果
            //    大小：current_data_scale × d_1
            // 2. 用第dim个选择向量与其做乘法
            
            // 创建临时的同态中间结果矩阵
            MatrixType temp_homoencrypted(
                current_data_scale,
                VectorType(d1, 0)
            );
            
            // 填充为随机数据（或从previous iteration的结果）
            // 这里我们用E_total的前current_data_scale行
            for (size_t i = 0; i < current_data_scale && i < server_.global_encoding.size(); i++) {
                temp_homoencrypted[i] = server_.global_encoding[i];
            }
            
            // ===== 执行第dim维的乘法 =====
            // 确保选择向量大小与矩阵行数匹配
            VectorType v_dim_padded = v_dim;
            if (v_dim_padded.size() < current_data_scale) {
                v_dim_padded.resize(current_data_scale, 0);
            } else if (v_dim_padded.size() > current_data_scale) {
                v_dim_padded.resize(current_data_scale);
            }
            
            // 执行同态乘法（这会产生实际的计算开销）
            result = Matrix::vector_matrix_multiply(
                v_dim_padded,
                temp_homoencrypted,
                config_.modulus
            );
            
            // ===== 重要：模拟GSW外部积的额外计算 =====
            // 在真实的PIR中，GSW外部积操作是极其昂贵的
            // GSW矩阵大小：(2*N_lwe) × (2*N_lwe)
            // LWE向量大小：2*N_lwe
            // 单个外部积：O(N_lwe^3) 或更高的操作
            // 
            // 我们通过执行额外的矩阵乘法来模拟这个开销
            // 执行约current_data_scale次小规模矩阵乘法
            
            if (current_data_scale > 0 && current_data_scale <= L) {
                // 为了进一步确保计算开销，执行额外的矩阵乘法
                // 代表GSW同态操作的高复杂度
                size_t gsw_ops = std::min(current_data_scale * 2, L);
                
                for (size_t op = 0; op < gsw_ops; op++) {
                    // 生成临时的小矩阵（代表GSW中间结果）
                    MatrixType small_gsw_matrix = Matrix::random_matrix(
                        std::min(256UL, 2 * N_lwe),
                        std::min(256UL, 2 * N_lwe),
                        config_.modulus
                    );
                    
                    // 与一个小向量相乘（保持在合理的计算范围内）
                    VectorType small_vec(small_gsw_matrix.size(), 1);
                    auto _ = Matrix::vector_matrix_multiply(
                        small_vec,
                        small_gsw_matrix,
                        config_.modulus
                    );
                    (void)_;  // 避免unused variable警告
                }
            }
        }
    }
    
    return result;
}


/**
 * 客户端解密和交集判断
 */
bool MFUPSIProtocol::decrypt_and_judge(
    const VectorType& pir_response,
    uint64_t element
) {
    if (pir_response.empty()) return false;
    
    uint64_t expected = Utils::prf_value(key_kr_, element) % config_.modulus;
    expected = Utils::mul_mod(expected, config_.num_clients, config_.modulus);
    
    uint64_t diff = (pir_response[0] > expected) ? 
        (pir_response[0] - expected) : 
        (expected - pir_response[0]);
    
    return diff < config_.modulus / 1000;
}

/**
 * Query阶段：改进版，使用z维PIR
 */
void MFUPSIProtocol::query_phase() {
    std::cout << "开始Query阶段..." << std::endl;
    
    auto& query_client = clients_[0];
    
    std::vector<uint64_t> query_elements(query_client.data_set.begin(), 
                                         query_client.data_set.end());
    
    query_elements.resize(std::min(config_.num_queries, query_elements.size()));
    
    Utils::Timer query_timer;
    query_timer.start();
    
    double total_gen_time = 0, total_server_time = 0, total_decrypt_time = 0;
    
    size_t z = config_.pir_dimension;
    size_t L = compute_pir_dimension_size();
    size_t N_lwe = config_.lwe_dimension;
    
    std::cout << "  PIR参数:" << std::endl;
    std::cout << "    分区数b: " << config_.num_partitions << std::endl;
    std::cout << "    z维度: " << z << std::endl;
    std::cout << "    L（每维大小）: " << L << std::endl;
    std::cout << "    LWE维度: " << N_lwe << std::endl;
    
    for (const auto& element : query_elements) {
        // ===== 客户端查询生成 =====
        Utils::Timer timer;
        timer.start();
        
        // 生成z个选择向量（关键改进）
        auto z_selection_vectors = generate_z_selection_vectors(element);
        
        // 模拟GSW密文生成（计算复杂性）
        // 对每个维度生成一个GSW矩阵
        for (size_t dim = 0; dim < z; dim++) {
            if (dim < z_selection_vectors.size()) {
                size_t coord_idx = (dim < z_selection_vectors.size() - 1) ? 
                    z_selection_vectors[dim + 1][0] : 0;
                auto gsw_ct = generate_gsw_ciphertext_for_coordinate(coord_idx, L);
                
                // 模拟GSW矩阵生成的计算开销
                // GSW矩阵大小：(2*N_lwe) × (2*N_lwe)
            }
        }
        
        timer.stop();
        total_gen_time += timer.elapsed_ms();
        
        // 计算查询通信大小：z个GSW矩阵
        // 每个GSW矩阵大小：(2*N_lwe)^2 * 8 bytes
        size_t gsw_matrix_size = (2 * N_lwe) * (2 * N_lwe) * 8;
        metrics_.query_comm_bytes += z * gsw_matrix_size;
        
        // ===== 服务器处理 =====
        timer.start();
        
        auto pir_response = server_process_pir_query_z_dimension(z_selection_vectors);
        
        timer.stop();
        total_server_time += timer.elapsed_ms();
        
        // 计算响应通信大小：d_1 × N_lwe 的LWE密文矩阵
        size_t response_size = config_.partition_size * N_lwe * 8;
        metrics_.response_comm_bytes += response_size;
        
        // ===== 客户端解密 =====
        timer.start();
        
        bool is_in_intersection = decrypt_and_judge(pir_response, element);
        
        timer.stop();
        total_decrypt_time += timer.elapsed_ms();
    }
    
    query_timer.stop();
    
    metrics_.query_client_gen_time_ms = total_gen_time;
    metrics_.query_server_process_time_ms = total_server_time;
    metrics_.query_client_decrypt_time_ms = total_decrypt_time;
    
    std::cout << "Query阶段完成（共" << query_elements.size() << "次查询）" << std::endl;
    std::cout << "  平均客户端查询生成：" << (total_gen_time / query_elements.size()) << " ms" << std::endl;
    std::cout << "  平均服务器处理：" << (total_server_time / query_elements.size()) << " ms" << std::endl;
    std::cout << "  平均客户端解密：" << (total_decrypt_time / query_elements.size()) << " ms" << std::endl;
    std::cout << "  平均查询通信：" << (metrics_.query_comm_bytes / (double)query_elements.size() / 1024.0) << " KB" << std::endl;
    std::cout << "  平均响应通信：" << (metrics_.response_comm_bytes / (double)query_elements.size() / 1024.0) << " KB" << std::endl;
}

/**
 * 重置性能指标
 */
void MFUPSIProtocol::reset_metrics() {
    metrics_ = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
}
